hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
h2oROC <- roc(pimaTest$Class, h2oPred$P, plot=TRUE)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,cv.hex))
localH2O <- h2o.init(nthread=16,Xmx="4g")
train.hex <- as.h2o(localH2O,pimaTrain)
test.hex <- as.h2o(localH2O,pimaTest)
cv.hex <- as.h2o(localH20, pimaCV)
predictors <- c(1:(ncol(train.hex)-1))
response <- ncol(train.hex)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,cv.hex))
test.hex <- as.h2o(localH20, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
localH2O <- h2o.init(nthread=16,Xmx="4g")
train.hex <- as.h2o(localH2O,pimaTrain)
test.hex <- as.h2o(localH2O,pimaTest)
predictors <- c(1:(ncol(train.hex)-1))
response <- ncol(train.hex)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
test.hex <- as.h2o(localH20, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
localH2O <- h2o.init(nthread=16,Xmx="4g")
test.hex <- as.h2o(localH20, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
h2oROC <- roc(pimaTest$Class, h2oPred$P, plot=TRUE)
localH2O <- h2o.init(nthread=16,Xmx="4g")
test.hex <- as.h2o(localH20, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
test.hex
localH2O <- h2o.init(nthread=16, max_mem_size="4g")
test.hex <- as.h2o(localH20, pimaCV)
test.hex <- as.h2o(localH2O, pimaCV)
cv.hex <- as.h2o(localH2O, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,cv.hex))
CVensemblePred <- (predict(rf, pimaCV, type = "prob")$P +
predict(rf1000, pimaCV, type = "prob")$P +
predict(knn, pimaCV, type = "prob")$P +
predict(knnScaled, pimaCV, type = "prob")$P +
predict(svmPred, pimaCV, type = "prob")$P +
predict(svmTunedGridPred, pimaCV, type = "prob")$P +
CVh2oPred$P)/7
predict(rf, pimaCV, type = "prob")$P
cvPreds <- c()
for(clf in c(rf, rf1000, knn, knnScaled, svmPred, svmTunedGrid)){
cvPreds <- c(cvPreds, predict(clf, pimaCv, type = "prob"))
}
trcontrol <- trainControl(classProbs = TRUE,
verboseIter = FALSE,
number = 10,
method = "repeatedcv",
summaryFunction=twoClassSummary)
set.seed(42)
rf <- train(Class ~. , data = pimaTrain, method="rf", metric="ROC",
trControl = trcontrol)
rfPred <- predict(rf, newdata=pimaTest, type = "prob")
#caret does not auto tune the number of trees so it must be specified
set.seed(42)
rf1000 <- train(Class ~. , data = pimaTrain, ntree = 1000, method="rf", metric="ROC",
trControl = trcontrol)
rf1000Pred <- predict(rf1000, pimaTest, type = "prob")
#train knn with ROC
set.seed(42)
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trcontrol)
knnPred <- predict(knn, newdata=pimaTest, type = "prob")
knnROC <- roc(pimaTest$Class, knnPred$P, plot=TRUE)
#look at the effect of scaling with knn
knnScaled <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20, preProcess = c("center", "scale"),
trControl = trcontrol)
knnScaledPred <- predict(knnScaled, newdata=pimaTest, type = "prob")
knnScaledROC <- roc(pimaTest$Class, knnScaledPred$P, plot=TRUE)
#train SVM generally
set.seed(42)
svm <- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
preProcess = c("center", "scale"),
trControl = trcontrol)
svmPred <- predict(svm, pimaTest, type = "prob")
svmROC <- roc(pimaTest$Class, svmPred, plot=TRUE)
#train SVM with tune length
set.seed(42)
svmTuned10 <- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
tuneLength = 10,
preProcess = c("center", "scale"),
trControl = trcontrol)
plot(svmTuned10)
svmTuned10Pred <- roc(pimaTest$Class, svmPredTuned10, plot=TRUE)
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred, plot=TRUE)
#train SVM with tune grid
set.seed(42)
svmGrid <- expand.grid(C=c(0.001,0.01,0.1,0.5,1,2), sigma = c(0.001,0.01,0.1,0.5,1,2))
svmTunedGrid<- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
tuneGrid = svmGrid,
preProcess = c("center", "scale"),
trControl = trcontrol)
svmTunedGridPred <- predict(svmTunedGrid, pimaTest, type = "prob")
svmTunedGridROC <- roc(pimaTest$Class, svmTunedGridPred, plot=TRUE)
svmTunedGridPred <- predict(svmTunedGrid, pimaTest, type = "prob")
svmTunedGridROC <- roc(pimaTest$Class, svmTunedGridPred, plot=TRUE)
svmTunedGridPred
svmTunedGridROC <- roc(pimaTest$Class, svmTunedGridPred$P, plot=TRUE)
cvPreds <- c()
for(clf in c(rf, rf1000, knn, knnScaled, svmPred, svmTunedGrid)){
cvPreds <- c(cvPreds, predict(clf, pimaCv, type = "prob"))
}
cvPreds <- c()
for(clf in c(rf, rf1000, knn, knnScaled, svmPred, svmTunedGrid)){
tempPred <- predict(clf, pimaCv, type = "prob")
cvPreds <- c(cvPreds, tempPred)
}
CVensemblePred <- (ens1$P + ens2$P + ens3$P + ens4$P +
ens5$P + ens6$P + CVh2oPred$P)/7
ens1 <- predict(rf, pimaCV, type = "prob")
ens2 <- predict(rf1000, pimaCV, type = "prob")
ens3 <- predict(knn, pimaCV, type = "prob")
ens4 <- predict(knnScaled, pimaCV, type = "prob")
ens5 <- predict(svmPred, pimaCV, type = "prob")
ens6 <- predict(svmTunedGridPred, pimaCV, type = "prob")
CVensemblePred <- (ens1$P + ens2$P + ens3$P + ens4$P +
ens5$P + ens6$P + CVh2oPred$P)/7
ens5 <- predict(svm, pimaCV, type = "prob")
ens6 <- predict(svmTunedGrid, pimaCV, type = "prob")
CVensemblePred <- (ens1$P + ens2$P + ens3$P + ens4$P +
ens5$P + ens6$P + CVh2oPred$P)/7
roc(pimaCV$Class, CVensemblePred, plot=TRUE)
roc(pimaCV$Class, CVh2oPred, plot=TRUE)
roc(pimaCV$Class, CVh2oPred$P, plot=TRUE)
CVh2oROC <- roc(pimaCV$Class, CVh2oPred$P, plot=FALSE)
CVensembleROC <- roc(pimaCV$Class, CVensemblePred, plot=FALSE)
plot(CVensembleROC, color = "red")
plot(CVh2oROC, color = "blue", add = TRUE)
plot(CVensembleROC, color = "red")
plot(CVh2oROC, color = "blue", add = TRUE)
plot(CVensembleROC, col= "red")
plot(CVh2oROC, col = "blue", add = TRUE)
rfROC <- roc(pimaTest$Class, rf$P, plot=TRUE)
rfROC <- roc(pimaTest$Class, rfPred$P, plot=TRUE)
rfROC
1:5
ROCS <- c(ensembleROC, h2oROC, svmTunedGridROC, knnScaledROC, rfROC)
mycolors <- c("red", "blue", "green", "purple", "orange")
for(i in 1:5){
if(i == 1){
plot(ROCS[i], col = mycolors[i])
}
else{
plot(ROCS[i], col = mycolors[i], add = TRUE)
}
}
ensembleROC <- roc(pimaTest$Class, ensemblePred, plot=TRUE)
nsemblePred <- (rfPred$P + rf1000Pred$P + knnPred$P + knnScaledPred$P +
svmPred$P + h2oPred$P + svmTunedGridPred$P)/7
ensembleROC <- roc(pimaTest$Class, ensemblePred, plot=TRUE)
ensemblePred <- (rfPred$P + rf1000Pred$P + knnPred$P + knnScaledPred$P +
svmPred$P + h2oPred$P + svmTunedGridPred$P)/7
ensembleROC <- roc(pimaTest$Class, ensemblePred, plot=TRUE)
ROCS <- c(ensembleROC, h2oROC, svmTunedGridROC, knnScaledROC, rfROC)
mycolors <- c("red", "blue", "green", "purple", "orange")
for(i in 1:5){
if(i == 1){
plot(ROCS[i], col = mycolors[i])
}
else{
plot(ROCS[i], col = mycolors[i], add = TRUE)
}
}
plot(ensembleROC, col = "red")
plot(h2oROC, col = "blue", add = T)
plot(svmTunedGridROC, col = "green", add = T)
plot(knnScaledROC, col = "purple", add = T)
plot(rfOC, col = "orange", add = T)
plot(rfROC, col = "orange", add = T)
plot(ensembleROC, col = "red")
plot(h2oROC, col = "blue", add = T)
plot(svmTunedGridROC, col = "orange", add = T)
plot(knnScaledROC, col = "green", add = T)
plot(rfROC, col = "purple", add = T)
plot(ensembleROC, col = "red")
plot(h2oROC, col = "blue", add = T)
plot(svmTunedGridROC, col = "green", add = T)
plot(knnScaledROC, col = "orange", add = T)
plot(rfROC, col = "purple", add = T)
plot(ensembleROC, col = "black")
plot(h2oROC, col = "red", add = T)
plot(svmTunedGridROC, col = "green", add = T)
plot(knnScaledROC, col = "orange", add = T)
plot(rfROC, col = "blue", add = T)
ensembleROC
h2oROC
rfROC
qplot(pimaTrain$Class)
500/768
svmLinear <- train(Class ~ . , data = pimaTrain, method="svmLinear", metric="ROC",
preProcess = c("center", "scale"),
trControl = trcontrol)
svmLinearPred <- predict(svmLinear, pimaTest, type = "prob")
svmLinearROC <- roc(pimaTest$Class, svmLinearPred, plot=TRUE)
trcontrol <- trainControl(classProbs = TRUE,
verboseIter = FALSE,
number = 10,
method = "repeatedcv",
summaryFunction=twoClassSummary)
svmLinear <- train(Class ~ . , data = pimaTrain, method="svmLinear", metric="ROC",
preProcess = c("center", "scale"),
trControl = trcontrol)
svmLinearPred <- predict(svmLinear, pimaTest, type = "prob")
svmLinearROC <- roc(pimaTest$Class, svmLinearPred, plot=TRUE)
svmLinearROC <- roc(pimaTest$Class, svmLinearPred$P, plot=TRUE)
svmLinearROC
svmROC
set.seed(42)
svm <- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
preProcess = c("center", "scale"),
trControl = trcontrol)
svmPred <- predict(svm, pimaTest, type = "prob")
svmROC <- roc(pimaTest$Class, svmPred, plot=TRUE)
svmROC <- roc(pimaTest$Class, svmPred$P, plot=TRUE)
svmROC
?h2o.deeplearning
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T,
nfolds = 10)
?h2o.shim
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T,
nfold = 10)
h2o.shim(enable = TRUE)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T,
nfolds = 10)
rf
set.seed(42)
#caret defaults to 500 trees
rf <- train(Class ~. , data = pimaTrain, method="rf", metric="ROC",
trControl = trcontrol)
#typical prediction, specification of newdata= is unncessary
#type = "prob" allows for ROC curve to be produced
rfPred <- predict(rf, newdata=pimaTest, type = "prob")
rfROC <- roc(pimaTest$Class, rfPred$P, plot=TRUE)
rf
rfROC
set.seed(42)
rf1000 <- train(Class ~. , data = pimaTrain, ntree = 1000, method="rf", metric="ROC",
trControl = trcontrol)
rf1000Pred <- predict(rf1000, pimaTest, type = "prob")
rf1000ROC <- roc(pimaTest$Class, rf1000Pred$P, plot=TRUE)
rf1000$finalModel
rf1000ROC
set.seed(42)
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trcontrol)
knnPred <- predict(knn, newdata=pimaTest, type = "prob")
knnROC <- roc(pimaTest$Class, knnPred$P, plot=TRUE)
knn
plot(knn)
set.seed(42)
knnScaled <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20, preProcess = c("center", "scale"),
trControl = trcontrol)
knnScaledPred <- predict(knnScaled, newdata=pimaTest, type = "prob")
knnScaledROC <- roc(pimaTest$Class, knnScaledPred$P, plot=TRUE)
plot(knnScaled)
plot(knn)
names(pima)
str(pima)
qplot(BMI,Pedigree, data=pima)
qplot(BMI,Pedigree, data=pima) + scale_y_continuous(limits = c(0, 80)) + scale_x_continuous(limits = c(0, 80))
set.seed(42)
knnScaled <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20, preProcess = c("center", "scale"),
trControl = trcontrol)
knnScaledPred <- predict(knnScaled, newdata=pimaTest, type = "prob")
knnScaledROC <- roc(pimaTest$Class, knnScaledPred$P, plot=TRUE)
knn
knnROC
knnScaledROC
args(h2o.deeplearning)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T,
n_folds=10)
svm
svmLinear
svmROC
svmLinearROC
set.seed(42)
svmTuned10 <- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
tuneLength = 10,
preProcess = c("center", "scale"),
trControl = trcontrol)
plot(svmTuned10)
svmTuned10Pred <- roc(pimaTest$Class, svmPredTuned10, plot=TRUE)
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred, plot=TRUE)
#train SVM with tune grid
set.seed(42)
svmGrid <- expand.grid(C=c(0.001,0.01,0.1,0.5,1,2), sigma = c(0.001,0.01,0.1,0.5,1,2))
svmTunedGrid<- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
tuneGrid = svmGrid,
preProcess = c("center", "scale"),
trControl = trcontrol)
svmTunedGridPred <- predict(svmTunedGrid, pimaTest, type = "prob")
svmTunedGridROC <- roc(pimaTest$Class, svmTunedGridPred$P, plot=TRUE)
svmTune10
svmTuned10
svmTuned10ROC
svmTuned10ROC
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred, plot=TRUE)
svmTuned10Pred <- roc(pimaTest$Class, svmPredTuned10, plot=TRUE)
set.seed(42)
svmTuned10 <- train(Class ~ . , data = pimaTrain, method="svmRadial", metric="ROC",
tuneLength = 10,
preProcess = c("center", "scale"),
trControl = trcontrol)
plot(svmTuned10)
svmTuned10Pred <- roc(pimaTest$Class, svmPredTuned10, plot=TRUE)
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred, plot=TRUE)
svmTuned10Pred <- roc(pimaTest$Class, svmTuned10, plot=TRUE)
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred$P, plot=TRUE)
svmTuned10Pred <- predict(pimaTest$Class, svmTuned10, type = "prob")
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred$P, plot=TRUE)
svmTuned10Pred <- predict(svmTuned10, pimaTest, type = "prob")
svmTuned10ROC <- roc(pimaTest$Class, svmTuned10Pred$P, plot=TRUE)
svmTuned10Pred
svmTuned10ROC
svmTunedGrid
svmTunedGridROC
localH2O <- h2o.init(nthread=16, max_mem_size="4g")
train.hex <- as.h2o(localH2O,pimaTrain)
test.hex <- as.h2o(localH2O,pimaTest)
predictors <- c(1:(ncol(train.hex)-1))
response <- ncol(train.hex)
#note that nfolds is currently not supported.  Use dropout methods instead
#to help avoid overfitting
#documentation unclear if h2o automatically standarizes inputs or not
#current h2o implementation will automatically mean impute missing values
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
h2oROC <- roc(pimaTest$Class, h2oPred$P, plot=TRUE)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
h2oROC <- roc(pimaTest$Class, h2oPred$P, plot=TRUE)
h2oROC
ensembleROC
cv.hex <- as.h2o(localH2O, pimaCV)
CVh2oPred <- as.data.frame(h2o.predict(h2omodel,cv.hex))
CVh2oROC <- roc(pimaCV$Class, CVh2oPred$P, plot=FALSE)
#type each prediction function explicitely for ease of learning
#normally perform sapply on a dataframe
ens1 <- predict(rf, pimaCV, type = "prob")
ens2 <- predict(rf1000, pimaCV, type = "prob")
ens3 <- predict(knn, pimaCV, type = "prob")
ens4 <- predict(knnScaled, pimaCV, type = "prob")
ens5 <- predict(svm, pimaCV, type = "prob")
ens6 <- predict(svmTunedGrid, pimaCV, type = "prob")
CVensemblePred <- (ens1$P + ens2$P + ens3$P + ens4$P +
ens5$P + ens6$P + CVh2oPred$P)/7
CVensembleROC <- roc(pimaCV$Class, CVensemblePred, plot=FALSE)
CVh2oROC
CVensembleROC
roc(pimaCV$Class, ens2, plot=FALSE)
roc(pimaCV$Class, ens2$P, plot=FALSE)
roc(pimaCV$Class, ens4$P, plot=FALSE)
roc(pimaCV$Class, ens5$P, plot=FALSE)
lessFeaturesFit <- train(Class ~ .,
data = pimaTrain[, c("Triceps", "BMI", "Age", "Glucose")],
method = "rf")
knnScaled
plot(knnScaled)
rfPred
head(rfPred)
?train
pima2 <- read.csv("pima-indians-diabetes.data")
pima2 <- read.csv("pima-indians-diabetes.data", header=FALSE)
View(pima2)
