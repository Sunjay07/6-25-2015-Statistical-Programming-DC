1293/4048
install.packages('magrittr') # A Forward-Pipe Operator for R
# Provides a mechanism for chaining commands with a new forward-pipe operator, %>%.
library(magrittr)
c(## DATA IMPORT AND MANIPULATION
'lubridate', # makes it easier to work with dates and times by providing functions to identify and parse date-time data
'stringr', # makes it easier to work with strings
'sqldf', # for running SQL statements on R data frames, optimized for convenience
'jsonlite', # A Robust, High Performance JSON Parser and Generator for R
'xlsx', # provides R functions to read/write/format Excel 2007 and Excel 97/2000/XP/2003 file formats
'data.table', # Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all
'reshape2', # Flexibly restructure and aggregate data using just two functions: melt and dcast (or acast)
'tidyr', # an evolution of reshape2. It's designed specifically for data tidying (not general reshaping or aggregating) and works well with dplyr data pipelines
'dplyr', # a fast, consistent tool for working with data frame like objects, both in memory and out of memory
'broom', # Convert Statistical Analysis Objects into Tidy Data Frames
# 'RCurl', # general network (HTTP/FTP/...) client interface for R
'httr', # provides useful tools for working with HTTP
## EXPLORATORY DATA ANALYSIS AND VISUALIZATION
'ggplot2', # an implementation of the Grammar of Graphics
'RColorBrewer', # provides palettes for drawing nice maps shaded according to a variable
'ellipse', # functions for drawing ellipses and ellipse-like confidence regions
'animation', # a gallery of animations in statistics and utilities to create animations
'mcmcplots', # for visual diagnostics of posterior samples
'igraph', # Network analysis and visualization
'shiny', # elegant and powerful web framework for building interactive web applications using R
'ggvis', # implements a interactive grammar of graphics, taking the best parts of ggplot2, combining them with shiny's reactive framework and drawing web graphics using vega
## STATISTICAL MODELING AND MACHINE LEARNING
'tree', # classification and regression trees
'randomForest', # classification and regression based on a forest of trees using random inputs
'RandomFields', # Simulation and Analysis of Random Fields
'caret', # Misc functions for training and plotting classification and regression models
'tm', # a framework for text mining applications within R
'mclust', # Normal Mixture Modeling for Model-Based Clustering, Classification, and Density Estimation
'TSclust', # Time Series Clustering Utilities
'BayesLCA', # Bayesian Latent Class Analysis
'car', # Companion to Applied Regression. Esp. useful for ANOVA tables.
'arm', # functions for processing lm, glm, svy.glm, mer and polr outputs
'gbm', # Generalized Boosted Regression Models
'glmnet', # lasso and elastic-net regularized generalized linear models
'lme4', # linear mixed-effects models using S4 classes
'mvtnorm', # multivariate Normal and t Distributions
'sde', # Simulation and Inference for Stochastic Differential Equations
'coda', # Output analysis and diagnostics for Markov Chain Monte Carlo simulations
'lda', # Collapsed Gibbs sampling methods for topic models. This package implements latent Dirichlet allocation (LDA) and related models.
'forecast', # for easy forecasting of time series,
'qcc', # statistical quality control and QC charts
'mice', # multiple imputation using Fully Conditional Specification (FCS)
'mi', # Missing Data Imputation and Model Checking
## REPORTING
'xtable', # Export tables to LaTeX or HTML
'knitr', # A general-purpose package for dynamic report generation in R
'rmarkdown', # enables easy creation of dynamic documents, presentations, and reports from R
'stargazer', # LaTeX/HTML code and ASCII text for well-formatted regression and summary statistics tables
## MISCELLANEOUS
'devtools', # Tools to make developing R code easier
# 'sendmailR', # send email using R
'foreach', # Foreach looping construct for R
'doMC', # for multi-core processing
'gridExtra', # misc. high-level Grid functions
'twitteR', # R based Twitter client
'packrat', # Reproducible package management for R, more info @ http://rstudio.github.io/packrat/
'miniCRAN' # Tools to create an internally consistent, mini version of CRAN with selected packages only
) %>% install.packages
# Data Importing and Manipulation (not available through CRAN)
devtools::install_github("RcppCore/Rcpp") # Seamless R and C++ Integration
devtools::install_github("hadley/xml2") # a binding to libxml2, making it easy to work with HTML and XML from R
devtools::install_github("hadley/haven") # Read SPSS, Stata and SAS files from R
# Twitter's package to detect anomalies which is robust, from a statistical standpoint, in the presence of seasonality and an underlying trend
devtools::install_github("twitter/AnomalyDetection")
# shinyapps.io - Share your Shiny Applications Online
devtools::install_github('rstudio/shinyapps')
# The rticles package includes a set of R Markdown templates that enable authoring
# of R related journal and conference submissions, and creating e-books.
devtools::install_github("rstudio/rticles")
# ======= BAYESIAN STATISTICAL INFERENCE ==========
## JAGS:
# Install JAGS first from http://mcmc-jags.sourceforge.net
# Then:
install.packages('rjags') # Interface to the JAGS MCMC library
# MAY need to install rjags with:
# install.packages('rjags',configure.args="--with-jags-include=/usr/local/include/JAGS --with-jags-modules=/usr/local/lib/JAGS/modules-3")
## Stan:
Sys.setenv(MAKEFLAGS = "-j4")
source('http://mc-stan.org/rstan/install.R', echo = TRUE, max.deparse.length = 2000)
install_rstan(); rm(install_rstan)
# More info @ https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#how-to-install-rstan
## Howard Seltman's RUBE (Really Useful WinBUGS and JAGS Enhancer)
# Greatly facilitates the efficient and organized writing and running of Bayesian analyses using WinBUGS or JAGS from R
# Download from: http://www.stat.cmu.edu/~hseltman/rube/
# =================================================
## Bioconductor Packages
source("http://bioconductor.org/biocLite.R")
biocLite()
install.packages("devtools")
install.packages("devtools")
library(devtools)
?install_github
install_github('rCharts', 'ramnathv')
install.packages("shiny")
install.packages("caret")
install.packages(c("Rcpp","httpuv"))
install.packages(c("Rcpp", "httpuv"))
install.packages("xgboost")
devtools::install_github('dmlc/xgboost',subdir='R-package')
library(caret)
source('~/kaggle/otto/H2O_Benchmark.R')
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/paymentMetrics.R')
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/paymentMetrics.R')
View(RIpayments)
names(RIpayments)
head(RIpayments)
RIpayments <- read.csv("RI Summary Raw Data_061415.csv")
str(RIpayments)
RIpayments$RI.Eligible.Payments <- as.numeric(RIpayments$RI.Eligible.Payments)
View(RIpayments)
str(RIpayments)
RIpayments <- read.csv("RI Summary Raw Data_061415.csv")
str(RIpayments)
ri <- RIpayments$RI.Eligible.Payments
ri2 <- as.numeric(ri)
?as.numeric
ri2 <- as.double(ri)
ri[1]
levels(ri)
ri[ri == ""]
ri[ri == ""][1]
length(ri[ri == ""][1])
length(ri[ri != ""][1])
nchar(ri[ri == ""][1])
nchar(as.character(ri[ri == ""][1]))
ri2 <- as.numeric(as.character(ri))
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/paymentMetrics.R')
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/paymentMetrics.R')
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/issuerManip.R')
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/issuerManip.R')
names(negIssuers)
names(negCompany)
negIssuers <- df[df$TotalTransfer<0 & df$RI.Eligible.Payments >0, c("Insurance.Company.Name",
"State", "HIOS.ID", "ALL_NTransfer",
"RI.Eligible.Payments")]
negCompany <- unique(negIssuers$Insurance.Company.Name)
negCompanyState <- unique(negIssuers[,c("Insurance.Company.Name", "State")])
names(negCompany)
negIssuers <- negIssuers[!is.na(negIssuers$Insurance.Company.Name),]
negCompanyState <- negCompanyState[!is.na(negCompanyState$Insurance.Company.Name),]
source('~/kpmg/projects/Cohen RA RI/Payment Transfer/issuerManip.R')
superensemble2 <- read.csv("superEnsemble2.csv")
setwd("~/kaggle/westnile")
superensemble2 <- read.csv("superEnsemble2.csv")
hist(superensemble2$WnvPresent)
hist(sqrt(superensemble2$WnvPresent))
hist(log(sqrt(superensemble2$WnvPresent)))
hist((1+log(sqrt(superensemble2$WnvPresent)))**2)
hist((1+log(sqrt(superensemble2$WnvPresent))))
hist((1.12+log(sqrt(superensemble2$WnvPresent))))
superenesmble2T <- superensemble2
superensemble2T$WnvPresent <- 1.12+log(sqrt(superensemble2$WnvPresent))
superenesmble2T <- superensemble2
superenesmble2T$WnvPresent <- 1.12+log(sqrt(superensemble2$WnvPresent))
blender <- (adaGood +
etc1000G + svcGood + glmforum + logreg84 + nnv2 + nn6 + superensemble2T)/8
blender$Id <- as.integer(btb$Id)
write.csv(blender, file="stBlend-super-8-T.csv", row.names=FALSE)
btb <- read.csv("beat_the_benchmark.csv")
kerasnn <- read.csv("keras-nn.csv")
lasNN <- read.csv("lasagne_west_nile.csv")
xgb <- read.csv("xgboost_starter_submission.csv")
etcC <- read.csv("clean-etc-0.56.csv")
adaetc <- read.csv("ada-etc-scaler-pca7-0.634.csv")
logi <- read.csv("logi-scaler-pca7-0.634.csv")
etc <- read.csv("etc-scaler-pca7-0.616.csv")
etcGood <- read.csv('etcGoodFeatures.csv')
svcGood <- read.csv('svcGoodFeatures.csv')
adaGood <- read.csv('ada20GoodFeatures.csv')
etc1000G <- read.csv("etc1000GoodFeatures.csv")
gbcGood <- read.csv("gbc11GoodFeatures.csv")
h2o3simple <- read.csv("h2o-3layer-simple.csv")
glmforum <- read.csv("glmforumpred.csv")
logreg84 <- read.csv("scripts/logreg84.csv")
nnv2 <- read.csv("scripts/nnv2.csv")
nn6 <- read.csv("scripts/nnsimple6.csv")
blender <- (adaGood +
etc1000G + svcGood + glmforum + logreg84 + nnv2 + nn6 + superensemble2T)/8
blender$Id <- as.integer(btb$Id)
write.csv(blender, file="stBlend-super-8-T.csv", row.names=FALSE)
blender <- (adaGood +
etc1000G + svcGood + glmforum + logreg84 + nnv2 + nn6 + superenesmble2T)/8
blender$Id <- as.integer(btb$Id)
write.csv(blender, file="stBlend-super-8-T.csv", row.names=FALSE)
h2omodel <- h2o.deeplearning(x=predictors,
y=response,
training_frame=train.hex,
classification_stop = -1,
activation="TanhWithDropout",
hidden=c(20,20,20),
hidden_dropout_ratio=c(0.5,0.5,0.5),
input_dropout_ratio=0.05,
epochs=50,
l1=1e-5,
l2=1e-5,
rho=0.99,
epsilon=1e-8,
train_samples_per_iteration=100,
max_w2=10,
seed=42,
balance_classes = T)
h2oPred <- as.data.frame(h2o.predict(h2omodel,test.hex))
roc(pimaTest$Positive, h2oPred$p0, plot=TRUE)
require(caret)
require(h2o)
require(GGally)
require(pROC)
#change this directory to wherever you put the data
setwd("~/Talks/6-25-2015 Statistical Programming DC")
set.seed(42)
source('~/Talks/6-25-2015 Statistical Programming DC/ml-compare.R')
source('~/Talks/6-25-2015 Statistical Programming DC/ml-compare.R')
names(pimaTrain)
firstTimeCaret <- train(Positive ~., data = pimaTrain, method = "rf")
ggpairs(pimaTrain, color="Positive", alpha = 0.3)
png("PimaPairs.png", height = 3000, width = 3000)
print(ggpairs(pimaTrain, color="Positive", alpha = 0.3))
dev.off()
qplot(pimaTrain$Positive)
rf <- train(Positive ~. , data = pima, method="rf", metric="ROC",
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
number = 10,
method = "repeatedcv",
summaryFunction=twoClassSummary))
rf
rfPred <- predict(rf, newdata=pimaTest, type = "prob")
rf
rfPred <- predict(rf, newdata=pimaTest, type = "prob")
head(pimaTest)
str(pimaTest)
knn <- train(Positive ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
knnPred <- predict(knn, newdata=pimaTest, type = "prob")
names(pimaTrain)
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
pima <- read.csv("pima-indians-diabetes.data")
pnames <- c("NumPreg", "Glucose", "BloodPressure", "Triceps",
"Insulin", "BMI", "Pedigree", "Age", "Class")
names(pima) <- pnames
#make prediction column a factor otherwise caret will think it is a regression problem
pima$Class <- as.factor(pima$Class)
#separate data into train, test and cv sets = 60% train, 20% test, 20% cv
pima$set <- sample(c(1,2,3), nrow(pima), replace = TRUE, prob = c(0.6,0.2,0.2))
pimaTrain <- pima[pima$set == 1, pnames]
pimaTest <- pima[pima$set == 2, pnames]
pimaCV <- pima[pima$set == 3, pnames]
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
levels(pimaTrain)
levels(pimaTrain$Class)
make.names(levels(pimaTrain$Class))
pima <- read.csv("pima-indians-diabetes.data")
pnames <- c("NumPreg", "Glucose", "BloodPressure", "Triceps",
"Insulin", "BMI", "Pedigree", "Age", "Class")
names(pima) <- pnames
#make prediction column a factor otherwise caret will think it is a regression problem
pima$Class[pima$Class == 0 ] <- "Negative"
pima$Class[pima$Class == 1 ] <- "Positive"
#separate data into train, test and cv sets = 60% train, 20% test, 20% cv
pima$set <- sample(c(1,2,3), nrow(pima), replace = TRUE, prob = c(0.6,0.2,0.2))
pimaTrain <- pima[pima$set == 1, pnames]
pimaTest <- pima[pima$set == 2, pnames]
pimaCV <- pima[pima$set == 3, pnames]
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
knnPred <- predict(knn, newdata=pimaTest, type = "prob")
levels(pimaTrain$Class)
unique(pimaTrain$Class)
pima$Class <- as.factor(pima$Class)
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
str(pimaTrain)
pima$set <- sample(c(1,2,3), nrow(pima), replace = TRUE, prob = c(0.6,0.2,0.2))
pimaTrain <- pima[pima$set == 1, pnames]
pimaTest <- pima[pima$set == 2, pnames]
pimaCV <- pima[pima$set == 3, pnames]
knn <- train(Class ~ . , data = pimaTrain, method="knn", metric="ROC",
tuneLength = 20,
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
method = "repeatedcv",
number = 10,
summaryFunction=twoClassSummary))
knnPred <- predict(knn, newdata=pimaTest, type = "prob")
rf <- train(Class ~. , data = pima, method="rf", metric="ROC",
trControl = trainControl(classProbs = TRUE,
verboseIter = FALSE,
number = 10,
method = "repeatedcv",
summaryFunction=twoClassSummary))
rfPred <- predict(rf, newdata=pimaTest, type = "prob")
rf
plot(rf)
rfPred <- predict(rf, pimaTest)
names(pimaTest)
names(pimaTrain)
rf$set
knn$set
svm <- train(Class ~ pnames[-3] , data = pima, method="svm", metric="ROC",
trControl = trainControl(classProbs = TRUE, verboseIter = TRUE,
method = "LGOCV", number = 10))
svm <- train(Class ~ . , data = pimaTrain, method="svm", metric="ROC",
trControl = trainControl(classProbs = TRUE, verboseIter = TRUE,
method = "LGOCV", number = 10))
sessionInfo()
library(caret)
svm <- train(Class ~ . , data = pimaTrain, method="svm", metric="ROC",
trControl = trainControl(classProbs = TRUE, verboseIter = TRUE,
method = "LGOCV", number = 10))
